{"cells": [{"cell_type": "markdown", "id": "ad55328e-553f-42d4-8686-c747195feff5", "metadata": {}, "source": "#### Milestone 3 - Random Forest Test"}, {"cell_type": "code", "execution_count": 1, "id": "d935737a-7777-4606-9a05-c469afa1055d", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql.functions import col, isnan, count, when, isnull, size, split\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, LongType, FloatType, DateType\nfrom pyspark.sql.functions import col, regexp_replace\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator"}, {"cell_type": "code", "execution_count": 2, "id": "c6a93d39-0fc6-40c9-819a-30b7f8e0600f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/04/12 02:53:41 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n24/04/12 02:53:41 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n24/04/12 02:53:41 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n24/04/12 02:53:41 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "spark = SparkSession.builder.appName('final_project').getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "id": "0abde25e-1dc9-4f6f-920a-d15872dd3ee6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Put in your bucket and folder path without the csv file\nBUCKET = 'gs://ds5460-tlee-spring2024/notebooks/jupyter//data/usa/combined_datasets/' \n\ndata_with_review = spark.read.csv(BUCKET + 'real-final-data.csv',inferSchema=True,header=True)\ndata_with_zero_review = spark.read.csv(BUCKET + 'target_column_with_zero_review.csv',inferSchema=True,header=True)"}, {"cell_type": "code", "execution_count": 4, "id": "64c20a31-6e14-4344-830a-605aa118b9f4", "metadata": {}, "outputs": [{"data": {"text/plain": "Row(host_total_listings_count=3.0, accommodates=8, num_bath=3.0, bedrooms=4.0, beds=6.0, price=500.0, amenities_count=14, essential_amenities=3, host_is_superhost='t', city='Broward County', room_type='Entire home/apt', full_time_host='f', host_verifications_clean='ep', target='Great')"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "# Double check the data was read in properly\ndata_with_review.head()"}, {"cell_type": "code", "execution_count": 5, "id": "6759c58e-7dd7-4701-a6a5-0c5dada48d91", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/04/12 02:54:01 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"}, {"data": {"text/plain": "Row(id=827736378366911479, host_id=475630606, host_since='2022-08-18', host_location='Unknown', host_is_superhost='f', host_listings_count=1.0, host_total_listings_count=3.0, host_has_profile_pic='t', host_identity_verified='t', neighborhood='Fort Lauderdale', latitude=26.09393643124416, longitude=-80.13759087771177, room_type='Entire home/apt', accommodates=2, num_bath=1.0, bedrooms=1.0, beds=1.0, price=222.0, number_of_reviews=0, review_scores_value=None, calculated_host_listings_count=1, city='Broward County', amenities_count=10, neighborhood_city='Fort Lauderdale Broward County', full_time_host='f', host_verifications_clean='p', essential_amenities=3)"}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "# Double check the data was read in properly\ndata_with_zero_review.head()"}, {"cell_type": "code", "execution_count": 6, "id": "cca55f0d-cde5-4a82-968d-fdef792778bf", "metadata": {}, "outputs": [], "source": "# Drop columns that can't be used in the feature pipeline as not applicable to zero reviews\ndata_with_zero_review = data_with_zero_review.drop('review_scores_value')\ndata_with_zero_review = data_with_zero_review.drop('number_of_reviews')"}, {"cell_type": "code", "execution_count": 7, "id": "23c03b58-9c70-4463-bb2b-f9de056a3d90", "metadata": {}, "outputs": [{"data": {"text/plain": "['host_total_listings_count',\n 'accommodates',\n 'num_bath',\n 'bedrooms',\n 'beds',\n 'price',\n 'amenities_count',\n 'essential_amenities',\n 'host_is_superhost',\n 'city',\n 'room_type',\n 'full_time_host',\n 'host_verifications_clean',\n 'target']"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "# Double check the columns in data_with_review\ndata_with_review.columns"}, {"cell_type": "markdown", "id": "1ee8a638-7570-44c3-9afa-2cd5ac03d459", "metadata": {}, "source": "### Create the Feature Pipeline"}, {"cell_type": "code", "execution_count": 8, "id": "eff8c70e-0800-424a-b6e2-355ed88e6d74", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# List of string features to be indexed and the features that are already numeric\nstringFeatures = ['host_is_superhost', 'city', 'room_type', 'full_time_host', 'host_verifications_clean']\n\nnumericFeatures = ['host_total_listings_count', 'accommodates', \n                   'num_bath','bedrooms', 'beds', 'price',\n                   'amenities_count', 'essential_amenities']\n\n# Create StringIndexer stages for the stringFeatures - call the numeric version as _indexed\nindexers = [StringIndexer(inputCol=column, outputCol=column+\"_indexed\", stringOrderType=\"alphabetAsc\").setHandleInvalid(\"skip\")\n            for column in stringFeatures]\n\n# Create a StringIndexer for the target column and naming it as target_label after converting it to numeric\nlabelIndexer = StringIndexer(inputCol='target', outputCol='target_label').setHandleInvalid(\"skip\")\n\n# Create VectorAssembler stage for the features\nassemblerInputs = [column+\"_indexed\" for column in stringFeatures] + numericFeatures\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n\n# Create and run the pipeline with the target indexer added to pipeline\npipeline = Pipeline(stages=indexers + [assembler, labelIndexer])\n\n# Fit the pipeline on the training data - which is all of data that has reviews\npipelineModel = pipeline.fit(data_with_review)\n\n# Alternative code if we wanted to do the train/test split earlier\n# trainingDataTransformed = pipelineModel.transform(trainingData)\n# testDataTransformed = pipelineModel.transform(testData)\n\n# Apply the pipeline on the data_with_review - trainingDataTransformed seen below will have to go through a train/test split\ntrainingDataTransformed = pipelineModel.transform(data_with_review)\n\n\n# To apply the pipeline on the data_with_zero_review, which is missing the target, we need to do the following:\n# Extracting the transformation stages from the fitted pipeline model\n# Excldue the LabelIndexer from final pipeline stage as we are applying on the prediction dataset\ntransformationStages = pipelineModel.stages[:-1]\n\n# Manually apply each transformation stage to the data_with_zero_review\ntransformedData = data_with_zero_review\nfor stage in transformationStages:\n    transformedData = stage.transform(transformedData)\n\n# We now have dataWithZeroReviewTransformed which doesn't have the target_label column to see what is our final model predictions\ndataWithZeroReviewTransformed = transformedData"}, {"cell_type": "markdown", "id": "3e845627-fd7e-4249-93ec-ad3c9d5b5d38", "metadata": {}, "source": "### Check if Feature Pipeline was done properly"}, {"cell_type": "code", "execution_count": 9, "id": "51202296-412f-4f40-a82b-aff4612eaabc", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- host_total_listings_count: double (nullable = true)\n |-- accommodates: integer (nullable = true)\n |-- num_bath: double (nullable = true)\n |-- bedrooms: double (nullable = true)\n |-- beds: double (nullable = true)\n |-- price: double (nullable = true)\n |-- amenities_count: integer (nullable = true)\n |-- essential_amenities: integer (nullable = true)\n |-- host_is_superhost: string (nullable = true)\n |-- city: string (nullable = true)\n |-- room_type: string (nullable = true)\n |-- full_time_host: string (nullable = true)\n |-- host_verifications_clean: string (nullable = true)\n |-- target: string (nullable = true)\n |-- host_is_superhost_indexed: double (nullable = false)\n |-- city_indexed: double (nullable = false)\n |-- room_type_indexed: double (nullable = false)\n |-- full_time_host_indexed: double (nullable = false)\n |-- host_verifications_clean_indexed: double (nullable = false)\n |-- features: vector (nullable = true)\n |-- target_label: double (nullable = false)\n\n"}], "source": "trainingDataTransformed.printSchema()"}, {"cell_type": "code", "execution_count": 10, "id": "c67b36a8-81c6-44f4-9be4-540af713acae", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: long (nullable = true)\n |-- host_id: integer (nullable = true)\n |-- host_since: string (nullable = true)\n |-- host_location: string (nullable = true)\n |-- host_is_superhost: string (nullable = true)\n |-- host_listings_count: double (nullable = true)\n |-- host_total_listings_count: double (nullable = true)\n |-- host_has_profile_pic: string (nullable = true)\n |-- host_identity_verified: string (nullable = true)\n |-- neighborhood: string (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- room_type: string (nullable = true)\n |-- accommodates: integer (nullable = true)\n |-- num_bath: double (nullable = true)\n |-- bedrooms: double (nullable = true)\n |-- beds: double (nullable = true)\n |-- price: double (nullable = true)\n |-- calculated_host_listings_count: integer (nullable = true)\n |-- city: string (nullable = true)\n |-- amenities_count: integer (nullable = true)\n |-- neighborhood_city: string (nullable = true)\n |-- full_time_host: string (nullable = true)\n |-- host_verifications_clean: string (nullable = true)\n |-- essential_amenities: integer (nullable = true)\n |-- host_is_superhost_indexed: double (nullable = false)\n |-- city_indexed: double (nullable = false)\n |-- room_type_indexed: double (nullable = false)\n |-- full_time_host_indexed: double (nullable = false)\n |-- host_verifications_clean_indexed: double (nullable = false)\n |-- features: vector (nullable = true)\n\n"}], "source": "dataWithZeroReviewTransformed.printSchema()"}, {"cell_type": "code", "execution_count": 11, "id": "afc05628-cb65-4652-ad00-c8fc11d858e8", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------------------+------------+--------+--------+----+-----+---------------+-------------------+-----------------+--------------+---------------+--------------+------------------------+------+-------------------------+------------+-----------------+----------------------+--------------------------------+--------------------------------------------------------+------------+\n|host_total_listings_count|accommodates|num_bath|bedrooms|beds|price|amenities_count|essential_amenities|host_is_superhost|city          |room_type      |full_time_host|host_verifications_clean|target|host_is_superhost_indexed|city_indexed|room_type_indexed|full_time_host_indexed|host_verifications_clean_indexed|features                                                |target_label|\n+-------------------------+------------+--------+--------+----+-----+---------------+-------------------+-----------------+--------------+---------------+--------------+------------------------+------+-------------------------+------------+-----------------+----------------------+--------------------------------+--------------------------------------------------------+------------+\n|3.0                      |8           |3.0     |4.0     |6.0 |500.0|14             |3                  |t                |Broward County|Entire home/apt|f             |ep                      |Great |1.0                      |1.0         |0.0              |0.0                   |1.0                             |[1.0,1.0,0.0,0.0,1.0,3.0,8.0,3.0,4.0,6.0,500.0,14.0,3.0]|0.0         |\n+-------------------------+------------+--------+--------+----+-----+---------------+-------------------+-----------------+--------------+---------------+--------------+------------------------+------+-------------------------+------------+-----------------+----------------------+--------------------------------+--------------------------------------------------------+------------+\nonly showing top 1 row\n\n"}], "source": "trainingDataTransformed.show(n=1, truncate=False)"}, {"cell_type": "code", "execution_count": 12, "id": "6c13292e-734a-430b-994f-c36fd3b5c197", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------------------+--------------------------------+\n|host_verifications_clean|host_verifications_clean_indexed|\n+------------------------+--------------------------------+\n|                      ep|                             1.0|\n|                      pw|                             8.0|\n|                      ep|                             1.0|\n|                      ep|                             1.0|\n|                      ep|                             1.0|\n+------------------------+--------------------------------+\nonly showing top 5 rows\n\n+---------------+-----------------+\n|      room_type|room_type_indexed|\n+---------------+-----------------+\n|Entire home/apt|              0.0|\n|Entire home/apt|              0.0|\n|Entire home/apt|              0.0|\n|Entire home/apt|              0.0|\n|Entire home/apt|              0.0|\n|Entire home/apt|              0.0|\n|   Private room|              2.0|\n|   Private room|              2.0|\n|   Private room|              2.0|\n|   Private room|              2.0|\n+---------------+-----------------+\nonly showing top 10 rows\n\n"}], "source": "# Doing a quick check that the string indexer worked and converted the categorical values into an index\ntrainingDataTransformed.select('host_verifications_clean', 'host_verifications_clean_indexed').show(5)\n\ntrainingDataTransformed.select('room_type', 'room_type_indexed').show(10)"}, {"cell_type": "code", "execution_count": 15, "id": "97e554f8-e22f-4ad2-9f8b-ca5bcdde9cf2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+------------+\n| target|target_label|\n+-------+------------+\n|  Great|         0.0|\n|Average|         1.0|\n|Average|         1.0|\n|Average|         1.0|\n|  Great|         0.0|\n|Average|         1.0|\n|  Great|         0.0|\n|Average|         1.0|\n|Average|         1.0|\n|Average|         1.0|\n|  Great|         0.0|\n|Average|         1.0|\n|  Great|         0.0|\n|  Great|         0.0|\n|Average|         1.0|\n|Average|         1.0|\n|   Poor|         2.0|\n|  Great|         0.0|\n|  Great|         0.0|\n|Average|         1.0|\n+-------+------------+\nonly showing top 20 rows\n\n"}], "source": "# Checking that the target_label got created successfully\ntrainingDataTransformed.select('target', 'target_label').show(20)"}, {"cell_type": "code", "execution_count": 16, "id": "0917fa66-c4d0-4ad4-935a-efe69b5c6529", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------------------------------------------------------+------------+\n|features                                                   |target_label|\n+-----------------------------------------------------------+------------+\n|[1.0,1.0,0.0,0.0,1.0,3.0,8.0,3.0,4.0,6.0,500.0,14.0,3.0]   |0.0         |\n|[0.0,1.0,0.0,0.0,8.0,12.0,6.0,2.0,2.0,4.0,186.0,22.0,4.0]  |1.0         |\n|[0.0,1.0,0.0,0.0,1.0,20.0,7.0,2.0,2.0,5.0,297.0,17.0,3.0]  |1.0         |\n|[0.0,1.0,0.0,0.0,1.0,5.0,4.0,1.0,1.0,2.0,162.0,69.0,5.0]   |1.0         |\n|[0.0,1.0,0.0,0.0,1.0,17.0,2.0,1.0,1.0,1.0,92.0,17.0,4.0]   |0.0         |\n|[1.0,1.0,0.0,0.0,1.0,1930.0,6.0,2.0,2.0,4.0,258.0,38.0,5.0]|1.0         |\n|[1.0,1.0,2.0,0.0,4.0,1.0,4.0,1.0,1.0,2.0,100.0,72.0,4.0]   |0.0         |\n|[0.0,1.0,2.0,0.0,8.0,19.0,4.0,1.0,1.0,2.0,189.0,60.0,5.0]  |1.0         |\n|[1.0,1.0,2.0,0.0,1.0,2.0,3.0,1.0,1.0,1.0,63.0,67.0,5.0]    |1.0         |\n|[0.0,1.0,2.0,0.0,1.0,13.0,2.0,1.0,1.0,1.0,127.0,51.0,5.0]  |1.0         |\n|[0.0,1.0,2.0,0.0,1.0,112.0,4.0,2.0,1.0,1.0,300.0,81.0,5.0] |0.0         |\n|[0.0,1.0,0.0,0.0,1.0,14.0,6.0,2.0,2.0,2.0,218.0,16.0,4.0]  |1.0         |\n|[0.0,1.0,0.0,0.0,1.0,2.0,4.0,1.0,2.0,3.0,155.0,52.0,5.0]   |0.0         |\n|[1.0,1.0,0.0,0.0,1.0,32.0,9.0,3.5,4.0,6.0,1764.0,57.0,5.0] |0.0         |\n|[1.0,1.0,0.0,0.0,1.0,10.0,2.0,1.0,1.0,1.0,91.0,52.0,5.0]   |1.0         |\n|[1.0,1.0,2.0,0.0,1.0,2.0,3.0,1.0,1.0,1.0,60.0,66.0,5.0]    |1.0         |\n|[0.0,1.0,0.0,0.0,1.0,292.0,6.0,1.0,2.0,3.0,313.0,24.0,4.0] |2.0         |\n|[1.0,1.0,0.0,0.0,1.0,72.0,2.0,1.0,1.0,1.0,101.0,54.0,5.0]  |0.0         |\n|[1.0,1.0,0.0,0.0,1.0,12.0,4.0,2.0,2.0,2.0,236.0,63.0,5.0]  |0.0         |\n|[1.0,1.0,0.0,0.0,1.0,23.0,6.0,3.0,3.0,3.0,440.0,52.0,5.0]  |1.0         |\n+-----------------------------------------------------------+------------+\nonly showing top 20 rows\n\n"}], "source": "# Examine all of the features with a particular target_label\ntrainingDataTransformed.select(\"features\", \"target_label\").show(truncate=False)"}, {"cell_type": "code", "execution_count": 17, "id": "eea2b23e-3e9c-45b9-b036-aacfc41683ee", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|            features|\n+--------------------+\n|[0.0,1.0,0.0,0.0,...|\n|[0.0,1.0,2.0,0.0,...|\n|[0.0,1.0,0.0,0.0,...|\n|[0.0,1.0,2.0,0.0,...|\n|[1.0,1.0,0.0,0.0,...|\n+--------------------+\nonly showing top 5 rows\n\n"}], "source": "# Examine if the dataWithZeroReviewTransformed features look like it was done correctly\ndataWithZeroReviewTransformed.select('features').show(5)"}, {"cell_type": "code", "execution_count": 18, "id": "44332c1c-eb1d-44d0-bde1-06b4edbbd1d7", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "For trainingDataTransformed:\nNumber of Rows: 143995, Number of Columns: 21\nFor dataWithZeroReviewTransformed:\nNumber of Rows: 40989, Number of Columns: 31\n"}], "source": "# See the count of each dataset to get an understanding on sizes:\nnum_rows = trainingDataTransformed.count()\nnum_columns = len(trainingDataTransformed.first())\n\nprint(\"For trainingDataTransformed:\")\nprint(f\"Number of Rows: {num_rows}, Number of Columns: {num_columns}\")\n\nnum_rows = dataWithZeroReviewTransformed.count()\nnum_columns = len(dataWithZeroReviewTransformed.first())\n\nprint(\"For dataWithZeroReviewTransformed:\")\nprint(f\"Number of Rows: {num_rows}, Number of Columns: {num_columns}\")"}, {"cell_type": "markdown", "id": "d248a33d-1b2c-409e-9c72-a8439ec5ac62", "metadata": {}, "source": "## Random Forest Model"}, {"cell_type": "code", "execution_count": 19, "id": "31e55832-22af-4c76-9da3-1cb615b4dd06", "metadata": {}, "outputs": [], "source": "# Do the train test split - we need to discuss what are we settng for the threshold\ntrain_data,test_data = trainingDataTransformed.randomSplit([0.7,0.3], seed=42)"}, {"cell_type": "code", "execution_count": 20, "id": "6ff6adbe-ef57-4cda-baaa-a56379f2993f", "metadata": {}, "outputs": [], "source": "rfc = RandomForestClassifier(labelCol='target_label',featuresCol='features', maxBins = 2200)"}, {"cell_type": "code", "execution_count": 21, "id": "75bbd13b-41c5-4b24-b253-e8fba7354279", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Fit to the train_data\nrfc_model = rfc.fit(train_data)"}, {"cell_type": "code", "execution_count": 22, "id": "402bd9f2-486f-4b2a-a049-37face526eda", "metadata": {}, "outputs": [], "source": "# Get the predictions for the test_data, which is the data with the ground truth known\nrfc_predictions = rfc_model.transform(test_data)"}, {"cell_type": "code", "execution_count": 23, "id": "a53abd34-bc44-4cd4-9637-7c62a042a8ad", "metadata": {}, "outputs": [], "source": "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"target_label\", predictionCol=\"prediction\", metricName=\"accuracy\")"}, {"cell_type": "code", "execution_count": 24, "id": "a26aa729-5eb7-4735-b8ba-1df3a4726430", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "rfc_acc = acc_evaluator.evaluate(rfc_predictions)"}, {"cell_type": "code", "execution_count": 25, "id": "b7365e28-c87a-4270-8c29-ffcdf0e9678b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "A random forest ensemble had an accuracy of: 57.95%\n"}], "source": "print('A random forest ensemble had an accuracy of: {0:2.2f}%'.format(rfc_acc*100))"}, {"cell_type": "code", "execution_count": 26, "id": "f4c31845-bc4a-470f-8904-179b163cb626", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 56:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------------------------------------------+------------+---------------------------------------------------------+------------------------------------------------------------+----------+\n|features                                                |target_label|rawPrediction                                            |probability                                                 |prediction|\n+--------------------------------------------------------+------------+---------------------------------------------------------+------------------------------------------------------------+----------+\n|[0.0,10.0,2.0,0.0,1.0,1.0,1.0,0.0,0.0,1.0,60.0,11.0,3.0]|0.0         |[10.493906030822693,7.4070682939240164,2.099025675253288]|[0.5246953015411348,0.37035341469620087,0.10495128376266442]|0.0       |\n|[0.0,7.0,2.0,0.0,1.0,1.0,1.0,0.0,1.0,1.0,59.0,27.0,3.0] |0.0         |[10.955398166344272,7.528243835699906,1.5163579979558188]|[0.5477699083172137,0.3764121917849954,0.07581789989779096] |0.0       |\n+--------------------------------------------------------+------------+---------------------------------------------------------+------------------------------------------------------------+----------+\nonly showing top 2 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Just seeing what is inside the rfc_predictions\nrfc_predictions.select(\"features\", \"target_label\", \"rawPrediction\", \"probability\", \"prediction\").show(truncate=False, n=2)"}, {"cell_type": "code", "execution_count": 27, "id": "4b791d95-d519-49cd-b242-cc2a724490d1", "metadata": {}, "outputs": [], "source": "# Applying the trained Random Forest model to the prediction dataset - the hold out zero reviews data\nzeroReviewPredictions = rfc_model.transform(dataWithZeroReviewTransformed)"}, {"cell_type": "code", "execution_count": 28, "id": "c2279892-bafb-419d-b6d7-c03415563d41", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------------------------------------------------------+---------------------------------------------------------+-----------------------------------------------------------+----------+\n|features                                                  |rawPrediction                                            |probability                                                |prediction|\n+----------------------------------------------------------+---------------------------------------------------------+-----------------------------------------------------------+----------+\n|[0.0,1.0,0.0,0.0,7.0,3.0,2.0,1.0,1.0,1.0,222.0,10.0,3.0]  |[10.268272811747906,7.588662116450266,2.14306507180183]  |[0.5134136405873952,0.3794331058225133,0.1071532535900915] |0.0       |\n|[0.0,1.0,2.0,0.0,1.0,112.0,2.0,2.0,2.0,4.0,500.0,29.0,3.0]|[6.539864888062047,10.663418849222504,2.7967162627154503]|[0.32699324440310235,0.5331709424611252,0.1398358131357725]|1.0       |\n|[0.0,1.0,0.0,0.0,4.0,6.0,16.0,4.0,6.0,12.0,868.0,68.0,5.0]|[7.20868238424544,10.975413122401623,1.8159044933529367] |[0.3604341192122721,0.5487706561200812,0.09079522466764685]|1.0       |\n|[0.0,1.0,2.0,0.0,1.0,3.0,2.0,1.0,1.0,2.0,47.0,14.0,3.0]   |[10.25803075819949,7.6089582376347344,2.133011004165774] |[0.5129015379099745,0.3804479118817367,0.1066505502082887] |0.0       |\n|[1.0,1.0,0.0,0.0,1.0,465.0,5.0,1.0,2.0,4.0,629.0,24.0,4.0]|[10.172579804772695,8.770693181109674,1.0567270141176315]|[0.5086289902386347,0.4385346590554837,0.05283635070588157]|0.0       |\n+----------------------------------------------------------+---------------------------------------------------------+-----------------------------------------------------------+----------+\nonly showing top 5 rows\n\n"}], "source": "# Displaying predictions, probabilities, and features\nzeroReviewPredictions.select(\"features\", \"rawPrediction\", \"probability\", \"prediction\").show(truncate=False, n=5)"}, {"cell_type": "code", "execution_count": 95, "id": "58f97155-d9c8-490d-95c0-17abc81ac457", "metadata": {}, "outputs": [], "source": "spark.stop()"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}