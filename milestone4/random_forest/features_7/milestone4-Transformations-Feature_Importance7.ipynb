{"cells": [{"cell_type": "code", "execution_count": 1, "id": "89e3c44f-e8f7-402d-b05b-8c85f586bf8f", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql.functions import col, isnan, count, when, isnull, size, split\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, LongType, FloatType, DateType\nfrom pyspark.sql.functions import col, regexp_replace\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler"}, {"cell_type": "code", "execution_count": 2, "id": "9a3ac87d-976e-4de6-8a6a-9d046310f493", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/04/14 03:55:15 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n24/04/14 03:55:15 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n24/04/14 03:55:15 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n24/04/14 03:55:15 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "spark = SparkSession.builder.appName('big_data_final_project_feature_importance').getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "id": "eebeb709-20cd-4d37-a10d-4d9d378bf693", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Put in your bucket and folder path without the csv file\nBUCKET = 'gs://ds5460-tlee-spring2024/notebooks/jupyter//data/usa/combined_datasets/' \n\ndata_with_review = spark.read.csv(BUCKET + 'real-final-data.csv',inferSchema=True,header=True)\ndata_with_zero_review = spark.read.csv(BUCKET + 'target_column_with_zero_review.csv',inferSchema=True,header=True)"}, {"cell_type": "code", "execution_count": 4, "id": "e91206c0-4d40-4c1d-b878-3a1563b25a3f", "metadata": {}, "outputs": [{"data": {"text/plain": "Row(host_total_listings_count=3.0, accommodates=8, num_bath=3.0, bedrooms=4.0, beds=6.0, price=500.0, amenities_count=14, essential_amenities=3, host_is_superhost='t', city='Broward County', room_type='Entire home/apt', full_time_host='f', host_verifications_clean='ep', target='Great')"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "# Double check the data was read in properly\ndata_with_review.head()"}, {"cell_type": "code", "execution_count": 5, "id": "90cddd7c-cdf8-4bf4-b5fc-dfce4e4520f8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/04/14 03:55:37 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"}, {"data": {"text/plain": "Row(id=827736378366911479, host_id=475630606, host_since='2022-08-18', host_location='Unknown', host_is_superhost='f', host_listings_count=1.0, host_total_listings_count=3.0, host_has_profile_pic='t', host_identity_verified='t', neighborhood='Fort Lauderdale', latitude=26.09393643124416, longitude=-80.13759087771177, room_type='Entire home/apt', accommodates=2, num_bath=1.0, bedrooms=1.0, beds=1.0, price=222.0, number_of_reviews=0, review_scores_value=None, calculated_host_listings_count=1, city='Broward County', amenities_count=10, neighborhood_city='Fort Lauderdale Broward County', full_time_host='f', host_verifications_clean='p', essential_amenities=3)"}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "# Double check the data was read in properly\ndata_with_zero_review.head()"}, {"cell_type": "code", "execution_count": 6, "id": "a541555d-6f69-45a8-9f4a-12a042616f76", "metadata": {}, "outputs": [], "source": "# Drop columns that can't be used in the feature pipeline as not applicable to zero reviews\ndata_with_zero_review = data_with_zero_review.drop('review_scores_value')\ndata_with_zero_review = data_with_zero_review.drop('number_of_reviews')"}, {"cell_type": "code", "execution_count": 7, "id": "27a75d54-6246-453c-9845-cd93e3ac77b1", "metadata": {}, "outputs": [{"data": {"text/plain": "['host_total_listings_count',\n 'accommodates',\n 'num_bath',\n 'bedrooms',\n 'beds',\n 'price',\n 'amenities_count',\n 'essential_amenities',\n 'host_is_superhost',\n 'city',\n 'room_type',\n 'full_time_host',\n 'host_verifications_clean',\n 'target']"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "# Double check the columns in data_with_review\ndata_with_review.columns"}, {"cell_type": "markdown", "id": "9c0e459d-dc84-43bd-9d89-3cf453dc1b1e", "metadata": {}, "source": "### Create the Feature Pipeline based on RF Feature Importance Graphic on 7 Features"}, {"cell_type": "code", "execution_count": 8, "id": "712f4d76-153c-4988-8d62-876fc2607b71", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# List of string features to be indexed and the features that are already numeric\nstringFeatures = ['host_is_superhost', 'city', 'full_time_host']\n\nnumericFeatures = ['host_total_listings_count', 'accommodates', 'price', 'amenities_count']\n\n# Create StringIndexer stages for the stringFeatures - call the numeric version as _indexed\nindexers = [StringIndexer(inputCol=column, outputCol=column+\"_indexed\", stringOrderType=\"alphabetAsc\").setHandleInvalid(\"skip\")\n            for column in stringFeatures]\n\n# Create a StringIndexer for the target column and naming it as target_label after converting it to numeric\nlabelIndexer = StringIndexer(inputCol='target', outputCol='target_label').setHandleInvalid(\"skip\")\n\n# Create VectorAssembler stage for the features\nassemblerInputs = [column+\"_indexed\" for column in stringFeatures] + numericFeatures\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n\n# Create and run the pipeline with the target indexer added to pipeline\npipeline = Pipeline(stages=indexers + [assembler, labelIndexer])\n\n# Fit the pipeline on the training data - which is all of data that has reviews\npipelineModel = pipeline.fit(data_with_review)\n\n# Alternative code if we wanted to do the train/test split earlier as it depends if we want to do 80/20 or 70/30.\n# trainingDataTransformed = pipelineModel.transform(trainingData)\n# testDataTransformed = pipelineModel.transform(testData)\n\n# Apply the pipeline on the data_with_review - trainingDataTransformed seen below will have to go through a train/test split\ntrainingDataTransformed = pipelineModel.transform(data_with_review)\n\n\n# To apply the pipeline on the data_with_zero_review, which is missing the target, we need to do the following:\n# Extracting the transformation stages from the fitted pipeline model\n# Excldue the LabelIndexer from final pipeline stage as we are applying on the prediction dataset\ntransformationStages = pipelineModel.stages[:-1]\n\n# Manually apply each transformation stage to the data_with_zero_review\ntransformedData = data_with_zero_review\nfor stage in transformationStages:\n    transformedData = stage.transform(transformedData)\n\n# We now have dataWithZeroReviewTransformed which doesn't have the target_label column to see what is our final model predictions\ndataWithZeroReviewTransformed = transformedData"}, {"cell_type": "markdown", "id": "0490ee44-fe73-4d6f-bcbd-aead70ff1bc0", "metadata": {}, "source": "### Check if Feature Pipeline was done properly"}, {"cell_type": "code", "execution_count": 9, "id": "0bc16f6b-8711-4fd1-909f-f42db89f707e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- host_total_listings_count: double (nullable = true)\n |-- accommodates: integer (nullable = true)\n |-- num_bath: double (nullable = true)\n |-- bedrooms: double (nullable = true)\n |-- beds: double (nullable = true)\n |-- price: double (nullable = true)\n |-- amenities_count: integer (nullable = true)\n |-- essential_amenities: integer (nullable = true)\n |-- host_is_superhost: string (nullable = true)\n |-- city: string (nullable = true)\n |-- room_type: string (nullable = true)\n |-- full_time_host: string (nullable = true)\n |-- host_verifications_clean: string (nullable = true)\n |-- target: string (nullable = true)\n |-- host_is_superhost_indexed: double (nullable = false)\n |-- city_indexed: double (nullable = false)\n |-- full_time_host_indexed: double (nullable = false)\n |-- features: vector (nullable = true)\n |-- target_label: double (nullable = false)\n\n"}], "source": "trainingDataTransformed.printSchema()"}, {"cell_type": "code", "execution_count": 10, "id": "b09615ed-a35e-4e98-beab-9ab1d3e1ee73", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: long (nullable = true)\n |-- host_id: integer (nullable = true)\n |-- host_since: string (nullable = true)\n |-- host_location: string (nullable = true)\n |-- host_is_superhost: string (nullable = true)\n |-- host_listings_count: double (nullable = true)\n |-- host_total_listings_count: double (nullable = true)\n |-- host_has_profile_pic: string (nullable = true)\n |-- host_identity_verified: string (nullable = true)\n |-- neighborhood: string (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- room_type: string (nullable = true)\n |-- accommodates: integer (nullable = true)\n |-- num_bath: double (nullable = true)\n |-- bedrooms: double (nullable = true)\n |-- beds: double (nullable = true)\n |-- price: double (nullable = true)\n |-- calculated_host_listings_count: integer (nullable = true)\n |-- city: string (nullable = true)\n |-- amenities_count: integer (nullable = true)\n |-- neighborhood_city: string (nullable = true)\n |-- full_time_host: string (nullable = true)\n |-- host_verifications_clean: string (nullable = true)\n |-- essential_amenities: integer (nullable = true)\n |-- host_is_superhost_indexed: double (nullable = false)\n |-- city_indexed: double (nullable = false)\n |-- full_time_host_indexed: double (nullable = false)\n |-- features: vector (nullable = true)\n\n"}], "source": "dataWithZeroReviewTransformed.printSchema()"}, {"cell_type": "code", "execution_count": 11, "id": "f72ea74e-81bc-4814-ab29-b17b808d6812", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------------------+------------+--------+--------+----+-----+---------------+-------------------+-----------------+--------------+---------------+--------------+------------------------+------+-------------------------+------------+----------------------+--------------------------------+------------+\n|host_total_listings_count|accommodates|num_bath|bedrooms|beds|price|amenities_count|essential_amenities|host_is_superhost|city          |room_type      |full_time_host|host_verifications_clean|target|host_is_superhost_indexed|city_indexed|full_time_host_indexed|features                        |target_label|\n+-------------------------+------------+--------+--------+----+-----+---------------+-------------------+-----------------+--------------+---------------+--------------+------------------------+------+-------------------------+------------+----------------------+--------------------------------+------------+\n|3.0                      |8           |3.0     |4.0     |6.0 |500.0|14             |3                  |t                |Broward County|Entire home/apt|f             |ep                      |Great |1.0                      |1.0         |0.0                   |[1.0,1.0,0.0,3.0,8.0,500.0,14.0]|0.0         |\n+-------------------------+------------+--------+--------+----+-----+---------------+-------------------+-----------------+--------------+---------------+--------------+------------------------+------+-------------------------+------------+----------------------+--------------------------------+------------+\nonly showing top 1 row\n\n"}], "source": "trainingDataTransformed.show(n=1, truncate=False)"}, {"cell_type": "code", "execution_count": 12, "id": "71894ea4-7b2d-4eb8-8fdd-cc67177892d6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------------+-------------------------+\n|host_is_superhost|host_is_superhost_indexed|\n+-----------------+-------------------------+\n|                t|                      1.0|\n|                f|                      0.0|\n|                f|                      0.0|\n|                f|                      0.0|\n|                f|                      0.0|\n+-----------------+-------------------------+\nonly showing top 5 rows\n\n+--------------+------------+\n|          city|city_indexed|\n+--------------+------------+\n|Broward County|         1.0|\n|Broward County|         1.0|\n|Broward County|         1.0|\n|Broward County|         1.0|\n|Broward County|         1.0|\n+--------------+------------+\nonly showing top 5 rows\n\n"}], "source": "# Doing a quick check that the string indexer worked and converted the categorical values into an index\ntrainingDataTransformed.select('host_is_superhost', 'host_is_superhost_indexed').show(5)\n\ntrainingDataTransformed.select('city', 'city_indexed').show(5)"}, {"cell_type": "code", "execution_count": 13, "id": "64c51a68-32a9-4162-97ad-6d2c67dbdca7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+------------+\n| target|target_label|\n+-------+------------+\n|  Great|         0.0|\n|Average|         1.0|\n|Average|         1.0|\n|Average|         1.0|\n|  Great|         0.0|\n|Average|         1.0|\n|  Great|         0.0|\n|Average|         1.0|\n|Average|         1.0|\n|Average|         1.0|\n|  Great|         0.0|\n|Average|         1.0|\n|  Great|         0.0|\n|  Great|         0.0|\n|Average|         1.0|\n|Average|         1.0|\n|   Poor|         2.0|\n|  Great|         0.0|\n|  Great|         0.0|\n|Average|         1.0|\n+-------+------------+\nonly showing top 20 rows\n\n"}], "source": "# Checking that the target_label got created successfully\ntrainingDataTransformed.select('target', 'target_label').show(20)"}, {"cell_type": "code", "execution_count": 14, "id": "1683c4de-bd50-4858-a081-02add3bf521d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------------------------------+------------+\n|features                           |target_label|\n+-----------------------------------+------------+\n|[1.0,1.0,0.0,3.0,8.0,500.0,14.0]   |0.0         |\n|[0.0,1.0,0.0,12.0,6.0,186.0,22.0]  |1.0         |\n|[0.0,1.0,0.0,20.0,7.0,297.0,17.0]  |1.0         |\n|[0.0,1.0,0.0,5.0,4.0,162.0,69.0]   |1.0         |\n|[0.0,1.0,0.0,17.0,2.0,92.0,17.0]   |0.0         |\n|[1.0,1.0,0.0,1930.0,6.0,258.0,38.0]|1.0         |\n|[1.0,1.0,0.0,1.0,4.0,100.0,72.0]   |0.0         |\n|[0.0,1.0,0.0,19.0,4.0,189.0,60.0]  |1.0         |\n|[1.0,1.0,0.0,2.0,3.0,63.0,67.0]    |1.0         |\n|[0.0,1.0,0.0,13.0,2.0,127.0,51.0]  |1.0         |\n|[0.0,1.0,0.0,112.0,4.0,300.0,81.0] |0.0         |\n|[0.0,1.0,0.0,14.0,6.0,218.0,16.0]  |1.0         |\n|[0.0,1.0,0.0,2.0,4.0,155.0,52.0]   |0.0         |\n|[1.0,1.0,0.0,32.0,9.0,1764.0,57.0] |0.0         |\n|[1.0,1.0,0.0,10.0,2.0,91.0,52.0]   |1.0         |\n|[1.0,1.0,0.0,2.0,3.0,60.0,66.0]    |1.0         |\n|[0.0,1.0,0.0,292.0,6.0,313.0,24.0] |2.0         |\n|[1.0,1.0,0.0,72.0,2.0,101.0,54.0]  |0.0         |\n|[1.0,1.0,0.0,12.0,4.0,236.0,63.0]  |0.0         |\n|[1.0,1.0,0.0,23.0,6.0,440.0,52.0]  |1.0         |\n+-----------------------------------+------------+\nonly showing top 20 rows\n\n"}], "source": "# Examine all of the features with a particular target_label\ntrainingDataTransformed.select(\"features\", \"target_label\").show(truncate=False)"}, {"cell_type": "code", "execution_count": 15, "id": "d4d9867a-8671-4de8-ad6f-b7a185a7c307", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|            features|\n+--------------------+\n|[0.0,1.0,0.0,3.0,...|\n|[0.0,1.0,0.0,112....|\n|[0.0,1.0,0.0,6.0,...|\n|[0.0,1.0,0.0,3.0,...|\n|[1.0,1.0,0.0,465....|\n+--------------------+\nonly showing top 5 rows\n\n"}], "source": "# Examine if the dataWithZeroReviewTransformed features look like it was done correctly\ndataWithZeroReviewTransformed.select('features').show(5)"}, {"cell_type": "code", "execution_count": 16, "id": "dde34989-4f1c-4527-980e-04fa0734bcae", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "For trainingDataTransformed:\nNumber of Rows: 143995, Number of Columns: 19\nFor dataWithZeroReviewTransformed:\nNumber of Rows: 40989, Number of Columns: 29\n"}], "source": "# See the count of each dataset to get an understanding on sizes:\nnum_rows = trainingDataTransformed.count()\nnum_columns = len(trainingDataTransformed.first())\n\nprint(\"For trainingDataTransformed:\")\nprint(f\"Number of Rows: {num_rows}, Number of Columns: {num_columns}\")\n\nnum_rows = dataWithZeroReviewTransformed.count()\nnum_columns = len(dataWithZeroReviewTransformed.first())\n\nprint(\"For dataWithZeroReviewTransformed:\")\nprint(f\"Number of Rows: {num_rows}, Number of Columns: {num_columns}\")"}, {"cell_type": "code", "execution_count": 17, "id": "08925b69-a3a6-4d2b-a93a-955ba73403ea", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Define the GCS bucket paths\ntrainingDataPath = \"gs://ds5460-tlee-spring2024/notebooks/jupyter/data/usa/combined_datasets/trainingDataTransformed_3.parquet\"\ntestDataPath = \"gs://ds5460-tlee-spring2024/notebooks/jupyter/data/usa/combined_datasets/dataWithZeroReviewTransformed_3.parquet\"\n\n# Write the DataFrames to Parquet files with overwrite\ntrainingDataTransformed.write.mode(\"overwrite\").parquet(trainingDataPath)\ndataWithZeroReviewTransformed.write.mode(\"overwrite\").parquet(testDataPath)\n"}, {"cell_type": "code", "execution_count": 18, "id": "c3eb91fa-0bb0-4a06-b95a-793983215288", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------------------+------------+--------+--------+----+-----+---------------+-------------------+-----------------+--------------+---------------+--------------+------------------------+-------+-------------------------+------------+----------------------+--------------------+------------+\n|host_total_listings_count|accommodates|num_bath|bedrooms|beds|price|amenities_count|essential_amenities|host_is_superhost|          city|      room_type|full_time_host|host_verifications_clean| target|host_is_superhost_indexed|city_indexed|full_time_host_indexed|            features|target_label|\n+-------------------------+------------+--------+--------+----+-----+---------------+-------------------+-----------------+--------------+---------------+--------------+------------------------+-------+-------------------------+------------+----------------------+--------------------+------------+\n|                      3.0|           8|     3.0|     4.0| 6.0|500.0|             14|                  3|                t|Broward County|Entire home/apt|             f|                      ep|  Great|                      1.0|         1.0|                   0.0|[1.0,1.0,0.0,3.0,...|         0.0|\n|                     12.0|           6|     2.0|     2.0| 4.0|186.0|             22|                  4|                f|Broward County|Entire home/apt|             f|                      pw|Average|                      0.0|         1.0|                   0.0|[0.0,1.0,0.0,12.0...|         1.0|\n+-------------------------+------------+--------+--------+----+-----+---------------+-------------------+-----------------+--------------+---------------+--------------+------------------------+-------+-------------------------+------------+----------------------+--------------------+------------+\nonly showing top 2 rows\n\n+------------------+---------+----------+-------------+-----------------+-------------------+-------------------------+--------------------+----------------------+---------------+-----------------+------------------+---------------+------------+--------+--------+----+-----+------------------------------+--------------+---------------+--------------------+--------------+------------------------+-------------------+-------------------------+------------+----------------------+--------------------+\n|                id|  host_id|host_since|host_location|host_is_superhost|host_listings_count|host_total_listings_count|host_has_profile_pic|host_identity_verified|   neighborhood|         latitude|         longitude|      room_type|accommodates|num_bath|bedrooms|beds|price|calculated_host_listings_count|          city|amenities_count|   neighborhood_city|full_time_host|host_verifications_clean|essential_amenities|host_is_superhost_indexed|city_indexed|full_time_host_indexed|            features|\n+------------------+---------+----------+-------------+-----------------+-------------------+-------------------------+--------------------+----------------------+---------------+-----------------+------------------+---------------+------------+--------+--------+----+-----+------------------------------+--------------+---------------+--------------------+--------------+------------------------+-------------------+-------------------------+------------+----------------------+--------------------+\n|827736378366911479|475630606|2022-08-18|      Unknown|                f|                1.0|                      3.0|                   t|                     t|Fort Lauderdale|26.09393643124416|-80.13759087771177|Entire home/apt|           2|     1.0|     1.0| 1.0|222.0|                             1|Broward County|             10|Fort Lauderdale B...|             f|                       p|                  3|                      0.0|         1.0|                   0.0|[0.0,1.0,0.0,3.0,...|\n|592589963829194972| 66506549|2016-04-09|Alpharetta GA|                f|                1.0|                    112.0|                   t|                     t|  Pompano Beach|         26.22385|         -80.09099|   Private room|           2|     2.0|     2.0| 4.0|500.0|                             5|Broward County|             29|Pompano Beach Bro...|             f|                      ep|                  3|                      0.0|         1.0|                   0.0|[0.0,1.0,0.0,112....|\n+------------------+---------+----------+-------------+-----------------+-------------------+-------------------------+--------------------+----------------------+---------------+-----------------+------------------+---------------+------------+--------+--------+----+-----+------------------------------+--------------+---------------+--------------------+--------------+------------------------+-------------------+-------------------------+------------+----------------------+--------------------+\nonly showing top 2 rows\n\n"}], "source": "# Read the Parquet files back into DataFrames\ntrainingDataRead = spark.read.format(\"parquet\").load(trainingDataPath)\ntestDataRead = spark.read.format(\"parquet\").load(testDataPath)\n\n# Show the content of the DataFrames to verify\ntrainingDataRead.show(2)\ntestDataRead.show(2)\n"}, {"cell_type": "code", "execution_count": 19, "id": "325d2383-4021-493d-b488-9362ff66c615", "metadata": {}, "outputs": [], "source": "spark.stop()"}, {"cell_type": "code", "execution_count": null, "id": "176dc690-cc67-458d-9f23-9f79da28caed", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}