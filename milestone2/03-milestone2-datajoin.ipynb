{"cells": [{"cell_type": "markdown", "id": "2bc17210-e9e8-460b-b74d-8943f26f2fdb", "metadata": {}, "source": "## Milestone 2 All US Cities Data Combined via Spark\n\nThe purpose of this notebook is to join our 3 regional cleaned datasets into a single large dataset via Spark.\n\nIssues encountered when combining:\n* Spark has a problem reading in some of our "}, {"cell_type": "code", "execution_count": 1, "id": "5a807266-fc3a-45d9-8bc5-d97fa10611a3", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql.functions import col, isnan, count, when, isnull, size, split\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, LongType, FloatType, DateType\nfrom pyspark.sql.functions import col, regexp_replace"}, {"cell_type": "code", "execution_count": 2, "id": "1d80ab9a-8315-40ba-b8f7-20fe8871c890", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/03/26 04:05:15 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n24/03/26 04:05:15 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n24/03/26 04:05:15 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n24/03/26 04:05:15 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "spark = SparkSession.builder.appName('final_project').getOrCreate()"}, {"cell_type": "code", "execution_count": 14, "id": "1e6e4978-403a-42f1-a3b9-7a67a2a0a42b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: double (nullable = true)\n |-- host_id: integer (nullable = true)\n |-- host_name: string (nullable = true)\n |-- host_since: string (nullable = true)\n |-- host_location: string (nullable = true)\n |-- host_response_time: string (nullable = true)\n |-- host_response_rate: float (nullable = true)\n |-- host_acceptance_rate: float (nullable = true)\n |-- host_is_superhost: string (nullable = true)\n |-- host_listings_count: integer (nullable = true)\n |-- host_total_listings_count: integer (nullable = true)\n |-- host_has_profile_pic: string (nullable = true)\n |-- host_identity_verified: string (nullable = true)\n |-- neighborhood: string (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- room_type: string (nullable = true)\n |-- accommodates: integer (nullable = true)\n |-- num_bath: double (nullable = true)\n |-- bedrooms: integer (nullable = true)\n |-- beds: integer (nullable = true)\n |-- price: integer (nullable = true)\n |-- number_of_reviews: integer (nullable = true)\n |-- review_scores_value: double (nullable = true)\n |-- calculated_host_listings_count: integer (nullable = true)\n |-- city: string (nullable = true)\n |-- amenities_count: integer (nullable = true)\n\n"}], "source": "# Save in case needed to use a schema\n# Note had to make host_response_rate and host_acceptance_rate as string or else the Null is picked up as unrecognized %\n# east_schema = StructType([\n#     StructField(\"id\", LongType(), True),\n#     StructField(\"host_id\", LongType(), True),\n#     StructField(\"host_name\", StringType(), True),\n#     StructField(\"host_since\", DateType(), True),\n#     StructField(\"host_location\", StringType(), True),\n#     StructField(\"host_response_time\", StringType(), True),\n#     StructField(\"host_response_rate\", StringType(), True),\n#     StructField(\"host_acceptance_rate\", StringType(), True),\n#     StructField(\"host_is_superhost\", StringType(), True),\n#     StructField(\"host_listings_count\", IntegerType(), True),\n#     StructField(\"host_total_listings_count\", IntegerType(), True),\n#     StructField(\"host_has_profile_pic\", StringType(), True),\n#     StructField(\"host_identity_verified\", StringType(), True),\n#     StructField(\"latitude\", LongType(), True),\n#     StructField(\"longitude\", LongType(), True),\n#     StructField(\"room_type\", StringType(), True),\n#     StructField(\"accommodates\", IntegerType(), True),\n#     StructField(\"num_bath\", FloatType(), True),\n#     StructField(\"bedrooms\", IntegerType(), True),\n#     StructField(\"beds\", IntegerType(), True),\n#     StructField(\"price\", FloatType(), True),\n#     StructField(\"number_of_reviews\", IntegerType(), True),\n#     StructField(\"review_scores_value\", FloatType(), True),\n#     StructField(\"calculated_host_listings_count\", IntegerType(), True),\n#     StructField(\"city\", StringType(), True),\n#     StructField(\"amenities_count\", IntegerType(), True)\n# ])\n\n\n# Provide the file path\neast_file = \"gs://ds5460-tlee-spring2024/notebooks/jupyter/data/usa/clean/east_coast_cities_cleaned-spark.csv\"\n\n\neast_df = spark.read.csv(east_file, header=True, inferSchema=True)# schema=east_schema) #inferSchema=True) # #schema=east_schema) #\n\n# Preprocess the 'host_response_rate' and 'host_acceptance_rate' to remove '%' and cast to float\neast_df = east_df.withColumn(\"host_response_rate\", regexp_replace(\"host_response_rate\", \"%\", \"\").cast(FloatType()))\neast_df = east_df.withColumn(\"host_acceptance_rate\", regexp_replace(\"host_acceptance_rate\", \"%\", \"\").cast(FloatType()))\n\neast_df.printSchema()\n"}, {"cell_type": "code", "execution_count": 17, "id": "e5b85d74-d30d-40fe-ad45-8e64a7a38a0c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: double (nullable = true)\n |-- host_id: integer (nullable = true)\n |-- host_name: string (nullable = true)\n |-- host_since: string (nullable = true)\n |-- host_location: string (nullable = true)\n |-- host_response_time: string (nullable = true)\n |-- host_response_rate: float (nullable = true)\n |-- host_acceptance_rate: float (nullable = true)\n |-- host_is_superhost: string (nullable = true)\n |-- host_listings_count: integer (nullable = true)\n |-- host_total_listings_count: integer (nullable = true)\n |-- host_has_profile_pic: string (nullable = true)\n |-- host_identity_verified: string (nullable = true)\n |-- neighborhood: string (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- room_type: string (nullable = true)\n |-- accommodates: integer (nullable = true)\n |-- bathrooms_text: string (nullable = true)\n |-- bedrooms: integer (nullable = true)\n |-- beds: integer (nullable = true)\n |-- price: integer (nullable = true)\n |-- number_of_reviews: integer (nullable = true)\n |-- review_scores_value: double (nullable = true)\n |-- calculated_host_listings_count: integer (nullable = true)\n |-- num_bath: double (nullable = true)\n |-- city: string (nullable = true)\n |-- amenities_count: integer (nullable = true)\n\n"}], "source": "central_file = \"gs://ds5460-tlee-spring2024/notebooks/jupyter/data/usa/clean/central-region-cities-cleaned-spark.csv\"\ncentral_df = spark.read.csv(central_file, header=True, inferSchema=True)\ncentral_df = central_df.withColumn(\"host_response_rate\", regexp_replace(\"host_response_rate\", \"%\", \"\").cast(FloatType()))\ncentral_df = central_df.withColumn(\"host_acceptance_rate\", regexp_replace(\"host_acceptance_rate\", \"%\", \"\").cast(FloatType()))\ncentral_df.printSchema()"}, {"cell_type": "code", "execution_count": 19, "id": "2a51f353-306d-4f5e-b531-905277a99737", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: double (nullable = true)\n |-- host_id: integer (nullable = true)\n |-- host_name: string (nullable = true)\n |-- host_since: string (nullable = true)\n |-- host_location: string (nullable = true)\n |-- host_response_time: string (nullable = true)\n |-- host_response_rate: float (nullable = true)\n |-- host_acceptance_rate: float (nullable = true)\n |-- host_is_superhost: string (nullable = true)\n |-- host_listings_count: integer (nullable = true)\n |-- host_total_listings_count: integer (nullable = true)\n |-- host_has_profile_pic: string (nullable = true)\n |-- host_identity_verified: string (nullable = true)\n |-- neighborhood: string (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- room_type: string (nullable = true)\n |-- accommodates: integer (nullable = true)\n |-- bathrooms_text: string (nullable = true)\n |-- bedrooms: integer (nullable = true)\n |-- beds: integer (nullable = true)\n |-- price: integer (nullable = true)\n |-- number_of_reviews: integer (nullable = true)\n |-- review_scores_value: double (nullable = true)\n |-- calculated_host_listings_count: integer (nullable = true)\n |-- amenities_count: integer (nullable = true)\n |-- city: string (nullable = true)\n |-- num_bath: double (nullable = true)\n\n"}], "source": "west_file = \"gs://ds5460-tlee-spring2024/notebooks/jupyter/data/usa/clean/listings_detailed_clean_west-spark.csv\"\nwest_df = spark.read.csv(west_file, header=True, inferSchema=True)\nwest_df = west_df.withColumn(\"host_response_rate\", regexp_replace(\"host_response_rate\", \"%\", \"\").cast(FloatType()))\nwest_df = west_df.withColumn(\"host_acceptance_rate\", regexp_replace(\"host_acceptance_rate\", \"%\", \"\").cast(FloatType()))\nwest_df.printSchema()"}, {"cell_type": "code", "execution_count": 24, "id": "02a1f477-9883-49d5-a326-d1055756b9f2", "metadata": {}, "outputs": [], "source": "# Drop bathrooms_text from central and west:\ncentral_df = central_df.drop('bathrooms_text')\n\nwest_df = west_df.drop('bathrooms_text')"}, {"cell_type": "code", "execution_count": null, "id": "a930c185-b5fe-4634-b5cd-91bb9502a1be", "metadata": {}, "outputs": [], "source": "def count_nulls(df):\n    # Count nulls for each column. Omit isnan check to avoid data type mismatch.\n    null_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).collect()[0].asDict()\n    return null_counts\n\nnull_counts = count_nulls(east_df)\nprint(null_counts)\nprint(\"-----\")\nnull_counts = count_nulls(central_df)\nprint(null_counts)\nprint(\"-----\")\nnull_counts = count_nulls(west_df)\nprint(null_counts)"}, {"cell_type": "code", "execution_count": 16, "id": "d384b53c-56c7-4903-a1b3-7f7b6605522a", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>host_response_rate</th>\n      <td>17339</td>\n    </tr>\n    <tr>\n      <th>review_scores_value</th>\n      <td>15633</td>\n    </tr>\n    <tr>\n      <th>host_acceptance_rate</th>\n      <td>14827</td>\n    </tr>\n    <tr>\n      <th>id</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>bedrooms</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>calculated_host_listings_count</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>number_of_reviews</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>price</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>beds</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>accommodates</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>num_bath</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>host_id</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>longitude</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>latitude</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>host_total_listings_count</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>host_listings_count</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>amenities_count</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                count\nhost_response_rate              17339\nreview_scores_value             15633\nhost_acceptance_rate            14827\nid                                  0\nbedrooms                            0\ncalculated_host_listings_count      0\nnumber_of_reviews                   0\nprice                               0\nbeds                                0\naccommodates                        0\nnum_bath                            0\nhost_id                             0\nlongitude                           0\nlatitude                            0\nhost_total_listings_count           0\nhost_listings_count                 0\namenities_count                     0"}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": "def count_missings(spark_df,sort=True):\n    \"\"\"\n    Counts number of nulls and nans in each column\n    \"\"\"\n    df = spark_df.select([F.count(F.when(F.isnan(c) | F.isnull(c), c)).alias(c) for (c,c_type) in spark_df.dtypes if c_type not in ('timestamp', 'string', 'date')]).toPandas()\n\n    if len(df) == 0:\n        print(\"There are no any missing values!\")\n        return None\n\n    if sort:\n        return df.rename(index={0: 'count'}).T.sort_values(\"count\",ascending=False)\n\n    return df\n\ncount_missings(east_df)\n"}, {"cell_type": "code", "execution_count": 21, "id": "dc97c0d9-370d-440a-a54e-e151cd91ec3a", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>review_scores_value</th>\n      <td>7652</td>\n    </tr>\n    <tr>\n      <th>host_response_rate</th>\n      <td>7421</td>\n    </tr>\n    <tr>\n      <th>host_acceptance_rate</th>\n      <td>5974</td>\n    </tr>\n    <tr>\n      <th>id</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>beds</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>num_bath</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>calculated_host_listings_count</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>number_of_reviews</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>price</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>accommodates</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>bedrooms</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>host_id</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>longitude</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>latitude</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>host_total_listings_count</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>host_listings_count</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>amenities_count</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                count\nreview_scores_value              7652\nhost_response_rate               7421\nhost_acceptance_rate             5974\nid                                  0\nbeds                                0\nnum_bath                            0\ncalculated_host_listings_count      0\nnumber_of_reviews                   0\nprice                               0\naccommodates                        0\nbedrooms                            0\nhost_id                             0\nlongitude                           0\nlatitude                            0\nhost_total_listings_count           0\nhost_listings_count                 0\namenities_count                     0"}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": "count_missings(central_df)"}, {"cell_type": "code", "execution_count": 22, "id": "1c84d49e-283e-4411-816e-bc7f54d9af28", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>review_scores_value</th>\n      <td>18638</td>\n    </tr>\n    <tr>\n      <th>host_response_rate</th>\n      <td>12470</td>\n    </tr>\n    <tr>\n      <th>host_acceptance_rate</th>\n      <td>10445</td>\n    </tr>\n    <tr>\n      <th>id</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>beds</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>amenities_count</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>calculated_host_listings_count</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>number_of_reviews</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>price</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>accommodates</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>bedrooms</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>host_id</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>longitude</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>latitude</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>host_total_listings_count</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>host_listings_count</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>num_bath</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                count\nreview_scores_value             18638\nhost_response_rate              12470\nhost_acceptance_rate            10445\nid                                  0\nbeds                                0\namenities_count                     0\ncalculated_host_listings_count      0\nnumber_of_reviews                   0\nprice                               0\naccommodates                        0\nbedrooms                            0\nhost_id                             0\nlongitude                           0\nlatitude                            0\nhost_total_listings_count           0\nhost_listings_count                 0\nnum_bath                            0"}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": "count_missings(west_df)"}, {"cell_type": "code", "execution_count": 25, "id": "b0be7315-d1b1-4a45-a063-f88c6cad22f5", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The shape of the east DataFrame is: (68592, 27)\nThe shape of the central DataFrame is: (43067, 27)\nThe shape of the west DataFrame is: (74259, 27)\n"}], "source": "num_rows = east_df.count()\nnum_cols = len(east_df.columns)\n\nprint(f\"The shape of the east DataFrame is: ({num_rows}, {num_cols})\")\n\n\nnum_rows = central_df.count()\nnum_cols = len(central_df.columns)\n\nprint(f\"The shape of the central DataFrame is: ({num_rows}, {num_cols})\")\n\n\nnum_rows = west_df.count()\nnum_cols = len(west_df.columns)\n\nprint(f\"The shape of the west DataFrame is: ({num_rows}, {num_cols})\")\n"}, {"cell_type": "code", "execution_count": 26, "id": "e858c437-77a1-4f57-94ba-47488708aab6", "metadata": {}, "outputs": [], "source": "combined_df = east_df.unionByName(central_df).unionByName(west_df)"}, {"cell_type": "code", "execution_count": 27, "id": "266aeb18-df1d-4448-94d1-f03a4188daa0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The shape of the combined DataFrame is: (185918, 27)\n"}], "source": "num_rows = combined_df.count()\nnum_cols = len(combined_df.columns)\n\nprint(f\"The shape of the combined DataFrame is: ({num_rows}, {num_cols})\")"}, {"cell_type": "code", "execution_count": 28, "id": "dcda4cc3-c756-4143-973c-5fb7566101d9", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "output_path_csv = \"gs://ds5460-tlee-spring2024/notebooks/jupyter/data/usa/combined_datasets/combined_data_all_cities\"\n\n# Coalesce the DataFrame into 1 partition and write to a single CSV file\n# File will be initially called part-00000-5fbe87d4-4b54-4911-a6b9-9d38f18c7a19-c000\ncombined_df.coalesce(1).write.option(\"header\", \"true\").csv(output_path_csv)"}, {"cell_type": "code", "execution_count": 29, "id": "0af2fb3b-e737-4e3c-9d81-f6c93857549a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The shape of the combined DataFrame is: (185918, 27)\n"}], "source": "output_path_csv = \"gs://ds5460-tlee-spring2024/notebooks/jupyter/data/usa/combined_datasets/combined_data_all_cities\"\n\n\ncombined_listings_gcs_path = f\"{output_path_csv}/all_cities-final-spark-dataset.csv\"\ncombined_listings_df = spark.read.option(\"header\", \"true\").csv(combined_listings_gcs_path)\n\nnum_rows = combined_listings_df.count()\nnum_cols = len(combined_listings_df.columns)\n\n# Confirmed the shape is correct when reading the informaton back in:\nprint(f\"The shape of the combined DataFrame is: ({num_rows}, {num_cols})\")"}, {"cell_type": "code", "execution_count": 30, "id": "d3079b3d-847e-49ff-ba41-fcc69b1aebc9", "metadata": {}, "outputs": [], "source": "spark.stop()"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}
